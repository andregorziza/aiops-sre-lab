# AIOps + SRE Lab

Hands-on lab simulating real-world SRE scenarios with observability-first design, latency-driven autoscaling, and a clear path to Kubernetes, KEDA, and Infrastructure as Code.

---

## ğŸ¯ Goals
- Build a **realistic Node.js service** with controlled latency failures
- Instrument with **Prometheus metrics** (histograms)
- Visualize **p95 / p99** in **Grafana** (provisioned via Git)
- Implement **autoscaling based on latency** using **KEDA + Prometheus**
- Keep everything **reproducible and interview-ready**

---

## ğŸ§± Repository Structure
```
aiops-sre-lab/
â”œâ”€â”€ app/                 # Node.js app with latency injection
â”œâ”€â”€ docker-compose.yml   # Local stack (app + Prometheus + Grafana)
â”œâ”€â”€ observability/       # Prometheus & Grafana provisioning
â”œâ”€â”€ k8s/                 # Kubernetes manifests + KEDA
â”œâ”€â”€ incidents/           # Documented incident simulations
â”œâ”€â”€ runbooks/            # Operational runbooks
â”œâ”€â”€ docs/                # Step-by-step documentation
â”œâ”€â”€ terraform/           # (Future) IaC for clusters & observability
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start (Local)
```bash
docker-compose up --build
```

- App: http://localhost:3000
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3001 (admin / admin)

---

## ğŸ“Š Observability
- Metrics exposed at `/metrics`
- Latency measured with `http_request_duration_seconds` histogram
- p95 / p99 calculated via PromQL:
```promql
histogram_quantile(
  0.95,
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
)
```

Grafana dashboards are **provisioned from Git**.

---

## âš–ï¸ Autoscaling (Latency-Based)
- Uses **KEDA** with direct **PromQL execution**
- Avoids Custom Metrics API limitations
- Scales based on **user experience (latency)**, not CPU

---

## ğŸ§ª Load Test
```bash
kubectl run loadgen --rm -it \
  --image=curlimages/curl \
  --restart=Never -- sh

while true; do
  curl http://aiops-sre-app:3000/db
done
```

Observe scaling with:
```bash
kubectl get pods -w
kubectl get hpa -w
```

---

## ğŸ“š Documentation
- Step-by-step lab: `docs/how-to-lab.md`
- Kubernetes setup: `docs/how-to-kubernetes.md`
- KEDA autoscaling: `docs/how-to-keda.md`
- Incidents: `incidents/`
- Runbooks: `runbooks/`

---

## ğŸ§  Interview Notes
> "This is a controlled lab to simulate real failures, observability, RCA, and SRE automation. We instrumented histograms, calculated p95/p99 via PromQL, visualized in Grafana, and scaled using KEDA based on latency."

---

## ğŸ›£ï¸ Roadmap
- Terraform provisioning for Kubernetes & observability
- Alerting (SLO-based)
- AIOps anomaly detection
- Auto-remediation workflows
- ChatOps integrations

---

## âœ… Status
- Application: âœ…
- Metrics: âœ…
- Prometheus: âœ…
- Grafana dashboards: âœ…
- KEDA autoscaling: âœ…

---

**Built for learning, realism, and interviews.**

